---
layout: default
title: "LLM-UP: LLM-powered User Profiling for Search and Recommendation"
description: "SIGIR 2026 Workshop"

[//]: # (authors:)

[//]: # (  - name: "Hongzhi Yin")

[//]: # (    affiliation: "The University of Queensland, Brisbane, Australia")

[//]: # (  - name: "Wei Yuan")

[//]: # (    affiliation: "The University of Queensland, Brisbane, Australia")

[//]: # (  - name: "Yi Zhang")

[//]: # (    affiliation: "Anhui University, Hefei, China")

[//]: # (  - name: "Joel Mackenzie")

[//]: # (    affiliation: "The University of Queensland, Brisbane, Australia")

[//]: # (  - name: "Quoc Viet Hung Nguyen")

[//]: # (    affiliation: "Griffith University, Gold Coast, Australia")

[//]: # (  - name: "Wayne Xin Zhao")

[//]: # (    affiliation: "Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China")

[//]: # (  - name: "Yong Li")

[//]: # (    affiliation: "Department of Electronic Engineering, Tsinghua University, Beijing, China")

[//]: # (  - name: "Lina Yao")

[//]: # (    affiliation: "University of New South Wales, Sydney, Australia")
---



<style>
  body {
    font-size: 12px; /* Ê†πÊçÆÈúÄË¶ÅË∞ÉÊï¥Â≠ó‰ΩìÂ§ßÂ∞è */
  }
</style>


## Introduction

<div style="text-align: justify;">
The rapid advancement of large language models (LLMs) has opened new possibilities for understanding users in search and recommendation. While traditional behavior-based or feature-driven user models rely primarily on explicit interactions or handcrafted representations, LLMs introduce a fundamentally different paradigm: LLM-powered user profiling, where user preferences, intents, and contextual attributes can be extracted, summarized, or reasoned about directly through natural language. 
  This shift unlocks powerful new paths to achieve personalization but also raises pressing questions related to modeling fidelity, temporal dynamics, evaluation methodology, privacy, and responsible deployment. 
  The LLM-UP workshop aims to bring together researchers and practitioners to systematize emerging progress in LLM-powered user profiling, identify open challenges, and explore opportunities for integrating such techniques into search and recommendation pipelines. 
  The LLM-UP workshop adopts an interactive structure featuring lightning talks, panel discussions, and paper presentations to foster active engagement, cross-disciplinary dialogue, and community-driven agenda setting for this rapidly evolving field.
</div>

[//]: # (<p align="center">)

[//]: # (<img src="main.jpg" alt="GC" width="750">)

[//]: # (</p>)

<hr style="border-top: 1px solid #eee; margin: 40px 0 20px 0;">

## Time Schedule
**Workshop Date**: TBA (During SIGIR 2026)

**Venue**: TBA

<hr style="border-top: 1px solid #eee; margin: 40px 0 20px 0;">


## Program

The main focus for the workshop is to provide a venue for researchers and practitioners to get together to exchange ideas and do some consolidation on the emerging progress in LLM-powered user profiling:
(The exact time schedule for each part will be announced soon.)

**Section 1:  Welcome and Opening Remarks (30 mins)**

**Section 2:  Invited Keynote 1 & 2 (90 mins)**
  - We will invite two world-renowned experts to give talks and insights about LLM and recommender systems.

**Section 3: Paper Encore (60 mins)**
  - We will invite authors whose topic-related papers have been accepted to the main conference of SIGIR 2026 to share insights on LLM-powered user profiling. Unlike their formal presentations at the main conference, these talks will focus on interesting phenomena observed in their studies, as well as practical lessons learned and best practices derived from their experiments and real-world applications. 
    
**Section 4: Panel Discussion (45 mins)**
  - The interactive panel discussion will provide young scholars with valuable opportunities to engage directly with senior researchers and practitioners, ask questions, and gain deeper insights into emerging challenges and future directions in the field. 

**Section 5: Wrap-up and Closing Remarks (10 mins)**


<hr style="border-top: 1px solid #eee; margin: 40px 0 20px 0;">


## Organisers

<div style="text-align: justify;">
<ul style="list-style-type: disc; padding-left: 20px;">

<li><strong>Prof. Hongzhi Yin</strong>, full professor and ARC Future Fellow at the University of Queensland.</li>

<br>
<li><strong>Dr. Wei Yuan</strong>, postdoc at The University of Queensland. </li>
<br>
<li><strong>Mr. Yi Zhang</strong>, PhD student at Anhui University.</li>

<br>
<li><strong>Dr. Joel Mackenzie</strong>, senior lecturer and DECRA Fellow at The University of Queensland.</li>

<br>
<li><strong>Prof. Quoc Viet Hung Nguyen</strong>, associate Professor at Griffith University.</li>

<br>
<li><strong>Prof. Wayne Xin Zhao</strong>, full professor at Renmin University of China.</li>

<br>
<li><strong>Prof. Yong Li</strong>, full professor at Tsinghua University.</li>

<br>
<li><strong>Prof. Lina Yao</strong>, full professor at UNSW.</li>

</ul>
</div>

<hr style="border-top: 1px solid #eee; margin: 40px 0 20px 0;">

[//]: # (## Our Papers on Graph Condensation)

[//]: # ()
[//]: # (<ul style="list-style: none; padding-left: 0; font-size: smaller;">)

[//]: # (    <li style="margin-bottom: 5px;">)

[//]: # (        <strong><a href="https://arxiv.org/abs/2401.11720v2">Graph Condensation: A Survey</a></strong> )

[//]: # (        <a href="https://github.com/XYGaoG/Graph-Condensation-Papers">üìñ</a><br>)

[//]: # (        <em>Transactions on Knowledge and Data Engineering &#40;TKDE&#41;, 2025</em><br>)

[//]: # (        Xinyi Gao, Junliang Yu, Tong Chen, Guanhua Ye, Wentao Zhang, Hongzhi Yin)

[//]: # (    </li>)

[//]: # ()
[//]: # (    <li style="margin-bottom: 5px;">)

[//]: # (        <strong><a href="https://arxiv.org/abs/2405.13707">Rethinking and Accelerating Graph Condensation: A Training-Free Approach with Class Partition</a></strong><br>)

[//]: # (        <em>ACM Web Conference &#40;WWW&#41;, 2025</em><br>)

[//]: # (        Xinyi Gao, Guanhua Ye, Tong Chen, Wentao Zhang, Junliang Yu, Hongzhi Yin)

[//]: # (    </li>)

[//]: # ()
[//]: # (    <li style="margin-bottom: 5px;">)

[//]: # (        <strong><a href="https://arxiv.org/abs/2405.17003">Graph Condensation for Open-World Graph Learning</a></strong><br>)

[//]: # (        <em>ACM SIGKDD Conference on Knowledge Discovery and Data Mining &#40;SIGKDD&#41;, 2024</em><br>)

[//]: # (        Xinyi Gao, Tong Chen, Wentao Zhang, Yayong Li, Xiangguo Sun, Hongzhi Yin)

[//]: # (    </li>)

[//]: # ()
[//]: # (    <li style="margin-bottom: 5px;">)

[//]: # (        <strong><a href="https://arxiv.org/abs/2307.15967">Graph Condensation for Inductive Node Representation Learning</a></strong><br>)

[//]: # (        <em>IEEE International Conference on Data Engineering &#40;ICDE&#41;, 2024</em><br>)

[//]: # (        Xinyi Gao, Tong Chen, Yilong Zang, Wentao Zhang, Quoc Viet Hung Nguyen, Kai Zheng, Hongzhi Yin)

[//]: # (    </li>)

[//]: # ()
[//]: # (    <li style="margin-bottom: 5px;">)

[//]: # (        <strong><a href="https://arxiv.org/abs/2412.16250">Training-free Heterogeneous Graph Condensation via Data Selection</a></strong><br>)

[//]: # (        <em>IEEE International Conference on Data Engineering &#40;ICDE&#41;, 2025</em><br>)

[//]: # (        Yuxuan Liang, Wentao Zhang, Xinyi Gao, Ling Yang, Chong Chen, Hongzhi Yin, Yunhai Tong, Bin Cui)

[//]: # (    </li>)

[//]: # ()
[//]: # (    <li style="margin-bottom: 5px;">)

[//]: # (        <strong><a href="https://arxiv.org/abs/2406.13200">RobGC: Towards Robust Graph Condensation</a></strong><br>)

[//]: # (        Xinyi Gao, Hongzhi Yin, Tong Chen, Guanhua Ye, Wentao Zhang, Bin Cui)

[//]: # (    </li>)

[//]: # (</ul>)

